import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ğŸ“‚ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
file_path = r"C:\Users\kimge\OneDrive\ë¬¸ì„œ\Desktop\ê¹€ ê±´\ê°€ì²œëŒ€í•™êµ\2025ë…„ 4í•™ë…„ 1í•™ê¸°_ì‹œê°„í‘œ\ì¸ê³µì§€ëŠ¥ê°œë¡ \1_week_homework_iris\iris.csv"
df = pd.read_csv(file_path)

# ğŸ¨ ìŠ¤íƒ€ì¼ ì„¤ì •
sns.set_style("whitegrid")

# 2ï¸âƒ£ ì…ë ¥(X)ê³¼ ì¶œë ¥(y) ë¶„ë¦¬
X = df[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]  # ì…ë ¥ê°’
y = df['Name']  # ì¶œë ¥ê°’ (í’ˆì¢…)

# 3ï¸âƒ£ ë¼ë²¨ ì¸ì½”ë”© (í’ˆì¢…ì„ ìˆ«ìë¡œ ë³€í™˜)
encoder = LabelEncoder()
y = encoder.fit_transform(y)

# 4ï¸âƒ£ í•™ìŠµ(train) & í…ŒìŠ¤íŠ¸(test) ë°ì´í„° ë¶„í•  (75%: í•™ìŠµ, 25%: í…ŒìŠ¤íŠ¸)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# 5ï¸âƒ£ ë°ì´í„° ì •ê·œí™” (í‘œì¤€í™”)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 6ï¸âƒ£ ëœë¤ í¬ë ˆìŠ¤íŠ¸(Random Forest) ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
rf_model.fit(X_train_scaled, y_train)

# 7ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
y_pred = rf_model.predict(X_test_scaled)

# 8ï¸âƒ£ ëª¨ë¸ í‰ê°€ (ì •í™•ë„ & ë³´ê³ ì„œ ì¶œë ¥)
accuracy = accuracy_score(y_test, y_pred)
print(f"âœ… ëª¨ë¸ ì •í™•ë„: {accuracy:.4f}")  # ì˜ˆìƒ: 95~100% ì •í™•ë„

# ğŸ”¹ ì˜¤ë¥˜ ë°©ì§€: `classification_report()`ì—ì„œ ì‹¤ì œ y_testì˜ í´ë˜ìŠ¤ ëª©ë¡ìœ¼ë¡œ ì„¤ì •
actual_classes = sorted(set(y_test))  # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤ë§Œ ì‚¬ìš©
print("\nğŸ“Š ë¶„ë¥˜ ë¦¬í¬íŠ¸(Classification Report)")
print(classification_report(y_test, y_pred, target_names=encoder.inverse_transform(actual_classes)))

# ğŸ“Š Feature Importance ì‹œê°í™”
feature_importances = rf_model.feature_importances_  # ì¤‘ìš”ë„ ê°€ì ¸ì˜¤ê¸°
feature_names = X.columns  # íŠ¹ì„± ì´ë¦„

plt.figure(figsize=(7, 5))
sns.barplot(x=feature_importances, y=feature_names, palette="viridis")
plt.xlabel("Feature Importance Score")
plt.ylabel("Features")
plt.title("ğŸ” Feature Importance (Random Forest)")
plt.savefig("random_forest_feature_importance.png")  # ì´ë¯¸ì§€ ì €ì¥
plt.show()
