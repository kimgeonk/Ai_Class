Q1. 인공지능에서 지능에 해당하는 기능은 무엇인가?
A1. 문제를 해결하기 위해 학습하고 이해하는 능력으로 인간의 인지적인 기능을 모방하여 문제를 해결하기 위해 학습하고 이해하는 것, 크게 분류와 회귀로 나눠짐
분류 : 이상적인 값을 예측
회귀 : 연속된 값에서 1개의 값을 예측 

Q2. 인공지능의 종류 3가지에 대해서 설명하시오 (지도학습, 반지도학습, 강화학습)
A2. 지도학습 : 라벨이 있는 데이터를 입력하여 입력을 출력 매핑하여 일반적인 규칙을 학습
반지도학습 : 라벨이 없는 데이터를 입력하여 데이터의 패턴을 발견하여 학습
강화학습 : 보상이나 처벌을 통해 더 좋은 방법으로 학습 

Q3. 전통적인 프로그래밍 방법과 인공지능 프로그램의 차이점은 무엇인가?
A3. 전통적인 프로그램은 프로그래머가 규칙을 만들어 데이터를 처리하지만 인공지능 프로그램은 학습을 통해 스스로 규칙을 만들어 데이터를 처리한다. 

Q4. 딥러닝과 머신러닝의 차이점은 무엇인가?
A4. 머신러닝은 컴퓨터가 주어진 데이터를 학습하여 알고리즘 성능을 개선해 나가는 것으로 데이터의 특성을 추출하여 모델에 넣고 룰을 생성한다.
딥러닝은 신경망의 학습 알고리즘으로 원본 데이터를 모델에 넣어 모델에서 학습을 해 룰을 생성한다.

Q5. Classification과 Regression의 주된 차이점은?
A5. 분류 : 데이터를 특정 카테고리로 나누어 학습하는 방법으로 이상적인 값을 예측한다. ex) 사과, 배, 파인애플을 구분
회귀 : 종속 변수와 독립 변수 간의 관계를 이해하는 지도 학습으로 연속된 값에서 하나의 값을 예측한다. ex) 집 값을 예측 

Q6. 머신러닝에서 차원의 저주(curse of dimensionality)란?
A6. 차원이 증가할 수록 차원 내 개별 데이터의 수가 줄어들어 성능이 줄어드는 현상Q1. 인공지능에서 지능에 해당하는 기능은 무엇인가?
A1. 문제를 해결하기 위해 학습하고 이해하는 능력으로 인간의 인지적인 기능을 모방하여 문제를 해결하기 위해 학습하고 이해하는 것, 크게 분류와 회귀로 나눠짐
분류 : 이상적인 값을 예측
회귀 : 연속된 값에서 1개의 값을 예측 

Q2. 인공지능의 종류 3가지에 대해서 설명하시오 (지도학습, 반지도학습, 강화학습)
A2. 지도학습 : 라벨이 있는 데이터를 입력하여 입력을 출력 매핑하여 일반적인 규칙을 학습
반지도학습 : 라벨이 없는 데이터를 입력하여 데이터의 패턴을 발견하여 학습
강화학습 : 보상이나 처벌을 통해 더 좋은 방법으로 학습 

Q3. 전통적인 프로그래밍 방법과 인공지능 프로그램의 차이점은 무엇인가?
A3. 전통적인 프로그램은 프로그래머가 규칙을 만들어 데이터를 처리하지만 인공지능 프로그램은 학습을 통해 스스로 규칙을 만들어 데이터를 처리한다. 

Q4. 딥러닝과 머신러닝의 차이점은 무엇인가?
A4. 머신러닝은 컴퓨터가 주어진 데이터를 학습하여 알고리즘 성능을 개선해 나가는 것으로 데이터의 특성을 추출하여 모델에 넣고 룰을 생성한다.
딥러닝은 신경망의 학습 알고리즘으로 원본 데이터를 모델에 넣어 모델에서 학습을 해 룰을 생성한다.

Q5. Classification과 Regression의 주된 차이점은?
A5. 분류 : 데이터를 특정 카테고리로 나누어 학습하는 방법으로 이상적인 값을 예측한다. ex) 사과, 배, 파인애플을 구분
회귀 : 종속 변수와 독립 변수 간의 관계를 이해하는 지도 학습으로 연속된 값에서 하나의 값을 예측한다. ex) 집 값을 예측 

Q6. 머신러닝에서 차원의 저주(curse of dimensionality)란?
A6. 차원이 증가할 수록 차원 내 개별 데이터의 수가 줄어들어 성능이 줄어드는 현상. 차원이 많아지면 데이터가 멀리 떨어지게 되고 KNN 등의 알고리즘을 적용하기 어렵고
차원 사이의 빈 공간이 0으로 채워져 컴퓨터가 연산하는데 시간과 비용이 증가한다. 

Q7. Dimensionality Reduction는 왜 필요한가?
A7. 차원의 저주를 해결하기 위해 필요하다. 차원을 줄이면서 모델의 성능을 유지할 수 있다. 차원이 줄어들면 과적합을 방지할 수 있고 계산해야 할 비용이 줄어들어 예측을
빠르게 할 수 있다. 또한, 2차원,3차원으로 차원을 맞출 경우 데이터를 시각하여 볼 수 있다.

Q8. Ridge와 Lasso의 공통점과 차이점? (Regularization, 규제 , Scaling)
A8.Ridge(L2) : 릿지회귀로 λ라는 규제를 도입하여 loss를 계산할 때 가중치를 제곱하여 가중치를 0으로 수렴하게 만든다.
Lasso(L1) : 로쏘회귀로 λ라는 규제를 도입하여 loss를 계산할 때 가중치의 절댓값을 더해 가중치를 0으로 만든다. 
공통점 : lambda 값이 클수록 λ를 더 빠르게 0으로 보낸다. SSE(잔차)에 페널티를 더해 SSE를 최소화한다. 
차이점 : L2는 계수를 0에 가깝게 하지만 L1은 계수를 0에 만든다. 이 차이는 L2는 변수를 유지하고 L1은 불필요한 변수를 삭제시킨다. 

Q9. Overfitting vs. Underfitting
A9. 과잉적합 : 훈련 데이터의 outlier까지 전부 학습하여 학습하는 데이터에서는 성능이 좋지만 새로운 데이터에 대해서는 성능이 떨어지는 모델을 생성하는 것
과소적합 : 훈련 데이터에 대한 학습이 충분하지 않아 새로운 데이터에 대해서 성능이 떨어지는 모델을 생성하는 것
과잉적합은 노이즈를 제거하거난 모델을 단순하게 하여 해결
과소적합은 훈련 데이터를 추가하거나 모델을 복잡하게 하여 해결 

Q10. Feature Engineering과 Feature Selection의 차이점은?
A10. 

Q11. 전처리(Preprocessing)의 목적과 방법? (노이즈, 이상치, 결측치)
A11. 

Q12. EDA(Explorary Data Analysis)란? 데이터의 특성 파악(분포, 상관관계)
A12.

Q13. 회귀에서 절편과 기울기가 의미하는 바는? 딥러닝과 어떻게 연관되는가?
A13. 절편 : 편향(bias)으로 초기값을 나타낸다. 
기울기 : 가중치(weight)로 입력 데이터를 잘 설명할 수 있는 직선의 기울기로 입력과 출력에 대한 강도를 의미한다.
딥러닝의 퍼셉트론은 회귀에서의 가중치와 편향의 확장으로 딥러닝에서 학습은 가중치와 편향에 의해 결정된다.

Q14. Activation function 함수를 사용하는 이유? Softmax, Sigmoid 함수의 차이는?
A14. 활성화 함수는 입력의 총합을 받아서 출력값을 계산하는 함수로 선형 함수만 결합할 경우 성능이 향상되지 않기 때문에 비선형 함수를 섞어 성능을 개선할 수 있기 때문에
사용된다.
softmax : 여려 개의 입력을 받아 출력값의 합이 1이 되게 하는 함수 
sigmod : 0~1 사이의 출력값을 가지는 함수로 매끄럽게 변화하게 때문에 기존의 계단 함수의 단점인 x=0에서 미분이 가능하다. 따라서 더 정밀한 출력이 가능하다.
두 함수의 차이점은 softmax는 다중 클래스를 분류고 sigmod는 단일 클래스를 분류한다.
|항목|sigmod|softmax|
|출력 범위|(0,1)|(0,1), 전체 합이 1|
|사용 위치|이진 뷴류|다중 클래스 분류|
|다중 출력 지원|지원 안함|지원|
|수식의 형태|단일 지수 함수|전체 벡터를 고려한 정규화|
|확률 해석|1개의 클래스의 확률|각 클래스가 정답일 확률 분포|

Q15. Forward propagation, Backward propagation이란?
A15. 순전파 : 모든 연산에 대해 동일한 가중치를 적용하여 손실함수와 실제 값과의 차이를 계산한다.
역전파 : 순전파에서 계산한 오차를 가지고 역방향으로 grandient를 계산하여 각 층의 가중치와 편향 값을 변화시킴.

Q16. 손실함수란 무엇인가? 가장 많이 사용하는 손실함수 4가지 종류는?
A16. 손실함수는 알고지름이 얼마나 틀렸는지 수치적으로 나타낸 것
평균제곱오차(MSE) : 실제값과 예측값 사이의 오차 평균을 제곱하여 사용하는 손실함수
BinartCrossentropy : 이진 분류 문제를 해결하는데 사용하는 손실함수로, 레이블이 얼마나 떨어져 있는기 확인하여 손실을 계산함.
CategoriaclCrossentropy : 다중 분류 문제에서 사용하는 손실함수(원-핫 엔코딩으로 정답을 제공)
SparseCategoriaclCrossentropy : 정답이 원-핫 엔코딩이 아니라 정수로 주어질 경우 사용하는 손실함수 

Q17. 옵티마이저(optimizer)란 무엇일까? 옵티마이저와 손실함수의 차이점은?
Q17. 

Q18. 경사하강법 의미는? (확률적 경사하강법, 배치 경사하강법, 미치 배치경사하강법)
A18. 현재 위치에서 경사(기울기)를 이용하여 방향을 잡는 방법으로 가중치의 손실을 최소화하는 방향으로 움직일 수록 좋다.
확률적 경사하강법 : train에서 무작위로 1개의 sample를 뽑아 손실 함수의 경사를 따라 최적의 모델을 찾는 알고리즘
배치 경사하강법 : 전체 sample을 사용하여 경사 하강법을 실행 
미치 배치경사하강법 : train에서 무작위로 여러 개의 sample을 뽑아 경사 하강법을 수행하는 알고지름 

Q19. 교차검증, K-fold 교차검증의 의미와 차이
A19. 교차검증 : 

Q20. 하이퍼파라미터 튜닝이란 무엇인가?
A20. 

Q21. 결정트리에서 불순도(Impurity) – 지니 계수(Gini Index)란 무엇인가?
Q21. 

Q22. 앙상블이란 무엇인가?
A22. 동일한 딥러닝 신경망을 여러 개를 생성후 독립적으로 학습시켜 마지막에 합치는 방식이다. 

Q23. 부트 스트랩핑(bootstraping)이란 무엇인가?
A23. 

Q24. 배깅(Bagging)이란 무엇인가?
Q24. 

Q25. 주성분 분석(PCA) 이란 무엇인가?
A25. 

Q26. Dense Layer란 무엇인가?
A26. 
